<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Pushing the Limits of 3D Shape Generation at Scale</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Pushing the Limits of 3D Shape Generation at Scale</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Wang Yu</a><sup></sup>,</span>
            <span class="author-block">
              <a href="https://naiq.github.io">Xuelin Qian</a><sup></sup>,</span>
            <span class="author-block">
              <a href="https://jingyanghuo.github.io">Jingyang Huo</a><sup></sup>,
            </span>
            <span class="author-block">
              <a href="">Tiejun Huang</a><sup></sup>,
            </span>
            <span class="author-block">
              <a href="https://www.bozhao.me">Bo Zhao</a><sup></sup>,
            </span>
            <span class="author-block">
              <a href="https://yanweifu.github.io">Yanwei Fu</a><sup></sup>,
            </span>
<!--            <span class="author-block">-->
<!--              <a href="https://yanweifu.github.io">Ricardo Martin-Brualla</a><sup>2</sup>-->
<!--            </span>-->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup>Fudan University</span>
            <span class="author-block"><sup></sup>&nbsp&nbsp&nbspBeijing Academy of Artificial Intelligence</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="http://scale3d.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->

          </div>
        </div>
      </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="flex-row">
      <p style="text-align:justify">
        We present a significant breakthrough in 3D shape generation by scaling it to unprecedented dimensions. Through the adaptation of the Auto-Regressive model and the utilization of large language models, we have developed a remarkable model with an astounding 3.6 billion trainable parameters, establishing it as the largest 3D shape generation model to date. Our approach addresses the limitations of existing methods by enhancing the quality and diversity of generated 3D shapes. To tackle the challenges of high-resolution 3D shape generation, our model incorporates tri-plane features as latent representations, effectively reducing computational complexity. Additionally, we introduce a discrete codebook for efficient quantization of these representations. Leveraging the power of transformers, we enable multi-modal conditional generation, facilitating the production of diverse and visually impressive 3D shapes. To train our expansive model, we leverage an ensemble of publicly-available 3D datasets, consisting of a comprehensive collection of 216,659 objects from renowned repositories such as ModelNet40, ShapeNet, Pix3D, 3D-Future, and Objaverse. This diverse dataset empowers our model to learn from a wide range of object variations, bolstering its ability to generate high-quality and diverse 3D shapes. Through extensive experimentation, we demonstrate the remarkable efficacy of our approach in significantly improving the visual quality of generated 3D shapes. By pushing the boundaries of 3D generation, introducing novel methods for latent representation learning, and harnessing the power of transformers for multi-modal conditional generation, our contributions pave the way for substantial advancements in the field. Our work unlocks new possibilities for applications in gaming, virtual reality, product design, and other domains that demand high-quality and diverse 3D objects.
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Generation</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">Class-guide</h3>
        <div class="content has-text-justified">
          <p>

          </p>
        </div>
        <figure>
          <video class="centered" width="100%" autoplay="" loop="" muted="" playsinline="" >
            <source src="static/videos/plane.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="caption" style="text-align:center">
            Generated meshes of planes
          </p>
        </figure>
        <figure>
          <video class="centered" width="100%" autoplay="" loop="" muted="" playsinline="" >
            <source src="static/videos/car.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="caption" style="text-align:center">
            Generated meshes of cars
          </p>
        </figure>
        <figure>
          <video class="centered" width="100%" autoplay="" loop="" muted="" playsinline="" >
            <source src="static/videos/chair.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="caption" style="text-align:center">
            Generated meshes of chairs
          </p>
        </figure>
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Texture</h3>
        <div class="content has-text-justified">
          <p>
            The generated meshes by our model can be textured by using state-of-the-arts methods like <a href="https://github.com/TEXTurePaper/TEXTurePaper">TEXTure</a>.
          </p>
        </div>
        <figure style="width: 100%;">
          <a>
            <img width="100%" src="static/images/texture.png">
          </a>

        </figure>        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
<!--    <pre><code>@article{park2021nerfies,-->
<!--  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},-->
<!--  title     = {Nerfies: Deformable Neural Radiance Fields},-->
<!--  journal   = {ICCV},-->
<!--  year      = {2021},}-->
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="text-align:center">
            Source code mainly borrowed from <a href="https://keunhong.com/">Keunhong Park</a>'s
            <a href="https://nerfies.github.io/">Nerfies website</a> and
            <a href="https://meshdiffusion.github.io">	MeshDiffusion.</a>.
          </p>
        </div>
      </div>
    </div>  </div>
</footer>

</body>
</html>
